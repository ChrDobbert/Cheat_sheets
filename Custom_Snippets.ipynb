{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom Snippets.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "q7zf_LzJ45b5",
        "OWbTiL_T4m3G",
        "aqAn1KFHC_3t",
        "BaPIrLC16D6_"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOCdl1yHNyNW9Pqpk4+DWgg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChrDobbert/Cheat_sheets/blob/main/Custom_Snippets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7zf_LzJ45b5"
      },
      "source": [
        "# AutoML: Import libraries for H2O"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zkopq4N444sN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLKwZ9tlQYr8"
      },
      "source": [
        "# Save csv and download to desktop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rr4tXCcQdiW"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "df.to_csv('df.csv') \n",
        "files.download('df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWbTiL_T4m3G"
      },
      "source": [
        "# EDA: Import libraries for EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfDbSqXI4itz"
      },
      "source": [
        "import pandas as pd\n",
        "#pd.set_option(\"display.max.columns\", None)\n",
        "\n",
        "#re is for regular expression and .split method\n",
        "import re\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#for stuff in colaboratory?\n",
        "import pandas.util.testing as tm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import xlrd\n",
        "pd.set_option(\"display.max.columns\", None)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSowRXKV5BaY"
      },
      "source": [
        "# EDA: Look at the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t7UBjRo5GGo",
        "outputId": "e26d0b42-7428-469a-8a18-9dab6ecb960b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        }
      },
      "source": [
        "\n",
        "\n",
        "df.info()\n",
        "\n",
        "df.dtypes\n",
        "\n",
        "print(\"\\n\" + \"Head\" + \"\\n\" + \"_\"*80)\n",
        "df.head()\n",
        "\n",
        "print(\"\\n\" + \"Describe\" + \"\\n\" + \"_\"*80)\n",
        "df.describe()\n",
        "\n",
        "df.shape\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"Columns\" + \"\\n\" + \"_\"*80)\n",
        "col = df.columns\n",
        "#print(df[col[0:4]])\n",
        "\n",
        "df.columns\n",
        "\n",
        "print(\"\\n\" + \"Index\" + \"\\n\" + \"_\"*80)\n",
        "df.index"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1a647b688d55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqAn1KFHC_3t"
      },
      "source": [
        "# EDA: Filter for a column name"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exus3Vr8C7qq"
      },
      "source": [
        "df.filter(like=\"sepal\").head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaPIrLC16D6_"
      },
      "source": [
        "# EDA: Subsetting a dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nKlW8fY6GXP"
      },
      "source": [
        "print(df[df['class'] == \"Iris-virginica\"].head(10))\n",
        "\n",
        "print(df[df['sepal-length'] > 7].head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTaNID646N2k"
      },
      "source": [
        "# EDA: Counting & Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JmNyJxW6P-0"
      },
      "source": [
        "print(\"\\n\" + \"COUNT OF ENTRIES BY COLUMNS\" + \"\\n\" + \"_\"*80)\n",
        "count_per_class = df['class'].value_counts()\n",
        "print(count_per_class)\n",
        "\n",
        "print(\"\\n\" + \"NORMALIZED COUNT\" + \"\\n\" + \"_\"*80)\n",
        "print(df['class'].value_counts(normalize=True))\n",
        "\n",
        "# With Numpy For each store type, aggregate weekly_sales: get min, max, mean, and median\n",
        "#[df.columns[0:4] is used to select the columns of interest\n",
        "stats = df.groupby(\"class\")[df.columns[0:4]].agg([np.min, np.max, np.mean, np.median])\n",
        "stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDYWYtt16hEh"
      },
      "source": [
        "# EDA: Missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAsbSBSf6jMD"
      },
      "source": [
        "print(\"\\n\" + \"Any missing value?\" + \"\\n\" + \"_\"*80)\n",
        "\n",
        "print(df.isnull().values.any())\n",
        "\n",
        "print(\"\\n\" + \n",
        "      \"How many missing values?\" +\n",
        "      \"\\n\" + '_'*80)\n",
        "\n",
        "print(df.isnull().sum().sum())\n",
        "\n",
        "print(\"\\n\" + \"Where are the missing values?\" + \"\\n\" + \"_\"*80)\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2wduRXxcZZX"
      },
      "source": [
        "# EDA: Missing values table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVdEyXJ4cZvf"
      },
      "source": [
        "# Missing values\n",
        "def missing_values_table(df):\n",
        "        # Total missing values\n",
        "        mis_val = df.isnull().sum()\n",
        "        \n",
        "        # Percentage of missing values\n",
        "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
        "        \n",
        "        # Make a table with the results\n",
        "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
        "        \n",
        "        # Rename the columns\n",
        "        mis_val_table_ren_columns = mis_val_table.rename(\n",
        "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
        "        \n",
        "        # Sort the table by percentage of missing descending\n",
        "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
        "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
        "        '% of Total Values', ascending=False).round(1)\n",
        "        \n",
        "        # Print some summary information\n",
        "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
        "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
        "              \" columns that have missing values.\")\n",
        "        \n",
        "        # Return the dataframe with missing information\n",
        "        return mis_val_table_ren_columns\n",
        "\n",
        "\n",
        "missing_values= missing_values_table(city_day)\n",
        "missing_values.style.background_gradient(cmap='Reds')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fe2S1QUhGVG8"
      },
      "source": [
        "# EDA: change type of Columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAWm9sUB2vCB"
      },
      "source": [
        "# EDA Automatic with AutoViz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EALLPQr52x0v"
      },
      "source": [
        "''' Another great library for automatic EDA is AutoViz.\n",
        "With this library, several plots are generated with only 1 line of code.\n",
        "When combined with pandas_profiling, we obtain lots of information in a\n",
        "matter of seconds, using less then 5 lines of code. '''\n",
        "%pip install autoviz # installing and importing autoviz, another library for automatic data visualization\n",
        "from autoviz.AutoViz_Class import AutoViz_Class\n",
        "\n",
        "AV = AutoViz_Class()\n",
        "\n",
        "# Let's now visualize the plots generated by AutoViz.\n",
        "report_2 = AV.AutoViz(os.path.join(home, 'shootings_wash_post.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGPOgUgy29ZO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_2QLAuU29xV"
      },
      "source": [
        "#!pip install pandas-profiling\n",
        "import pandas_profiling # library for automatic EDA\n",
        "\n",
        "report = pandas_profiling.ProfileReport(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKtb-PzySR8n"
      },
      "source": [
        "# Feature Engineering: mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QuX5tMCRSWoe"
      },
      "source": [
        "def map_data(df):\n",
        "    '''\n",
        "    Function which takes the original dataframe and returns a \n",
        "    clean / updated dataframe\n",
        "    '''\n",
        "    # survived map\n",
        "    survived_map = {0: False, 1: True}\n",
        "    df['Survived'] = df['Survived'].map(survived_map)\n",
        "\n",
        "    # PClass map\n",
        "    pclass_map = {1: 'Upper Class', 2: 'Middle Class', 3: 'Lower Class'}\n",
        "    df['Pclass'] = df['Pclass'].map(pclass_map)\n",
        "\n",
        "    # Embarkation port map\n",
        "    port_map = {'S': 'Southampton', 'C': 'Cherbourg','Q':'Queenstown'}\n",
        "    df['Embarked'] = df['Embarked'].map(port_map)\n",
        "    \n",
        "    # add new column (FamilySize) to dataframe - sum of SibSp and Parch\n",
        "    df['FamilySize'] = df['SibSp'] + df['Parch']\n",
        "    \n",
        "    return df\n",
        "\n",
        "titanic_df = map_data(titanic_df)\n",
        "titanic_df.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hUPDGbXbLFs"
      },
      "source": [
        "# Feature Engineering: loc, creating variables, filter, change"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLyTRsILbLUl"
      },
      "source": [
        "# Creating a categorical variable for Ages\n",
        "df['AgeCat'] = ''\n",
        "df['AgeCat'].loc[(df['Age'] < 18)] = 'young'\n",
        "df['AgeCat'].loc[(df['Age'] >= 18) & (df['Age'] < 56)] = 'mature'\n",
        "df['AgeCat'].loc[(df['Age'] >= 56)] = 'senior'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezp0doA_GVWt"
      },
      "source": [
        "#df = pd.DataFrame({'float': [1.0],\n",
        "  #                   'int': [1],\n",
        "  #                   'datetime': [pd.Timestamp('20180310')],\n",
        "  #                   'string': ['foo']})\n",
        "  #df.dtypes\n",
        "  #float              float64\n",
        "  #int                  int64\n",
        "  #datetime    datetime64[ns]\n",
        "  #string              object\n",
        "\n",
        "df['class'] = df['class'].astype('category')\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvIWpQN65G6-"
      },
      "source": [
        "# Read datasets: CSV from url"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvqDWUWN5L7E"
      },
      "source": [
        "#source = \"url_address\"\n",
        "#df = pd.read_excel(source)\n",
        "\n",
        "\n",
        "#url = \"http://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "#column_names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
        "#df = pd.read_csv(url, names = column_names)\n",
        "                \n",
        "url = \"\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(type(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr7LOBx-7-hn"
      },
      "source": [
        "# Set up Kaggle API (Step 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZON2olg8AA4"
      },
      "source": [
        "!pip install kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0AJP_kl-pS3"
      },
      "source": [
        "# Set up Kaggle API (Step 2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl39Pshf-pES"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYCQKhtH9hJf"
      },
      "source": [
        "# Get datasets: CSV from Kaggle API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6mrGvFQ9hqj"
      },
      "source": [
        "#Next:\n",
        "#   “Copy the API Command” of the dataset that we want to import from Kaggle.\n",
        "#   !kaggle competitions download -c titanic\n",
        "\n",
        "#Let’s see the imported files:\n",
        "!ls\n",
        "\n",
        "#!rm remove files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EyN74ak9bEI"
      },
      "source": [
        "# Read datasets zip files: Kaggle API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXJW_hJT9bXT"
      },
      "source": [
        "#Now, the last step is to open the extracted files and get the data:\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(‘the-movies-dataset.zip’, ‘r’)\n",
        "zip_ref.extractall(‘files’)\n",
        "zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD1zpRtyXX7j"
      },
      "source": [
        "# Load files imported from Kaggle API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7yv-ZAk-XcKd"
      },
      "source": [
        "\n",
        "train = pd.read_csv(\"test.csv\")\n",
        "test = pd.read_csv(\"test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjd9j2ldCmiU"
      },
      "source": [
        "# Visualisation: Add sns.pairplot"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0jyIGojCqSD"
      },
      "source": [
        "sns.pairplot(df, #hue=\"class\",\n",
        "plot_kws=dict(s=100, linewidth=.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRT_lP2lCx2j"
      },
      "source": [
        "# Visualisation: Add sns.corr plot , correlation, heatmap"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGgGnWUvCyLH"
      },
      "source": [
        "colorMap = sns.color_palette(\"YlGnBu\", n_colors=5)\n",
        "\n",
        "mask = np.tril(df.corr())\n",
        "sns.heatmap(df.corr(), fmt=\".2g\", annot = True, cmap= colorMap, mask=mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFtEZzoLYPHA"
      },
      "source": [
        "# Visualisation: Add PPS, predictive power score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJaZBrldYXyE"
      },
      "source": [
        "!pip install ppscore\n",
        "\n",
        "import ppscore as pps\n",
        "\n",
        "df.columns\n",
        "\n",
        "col = df.columns\n",
        "print(df[col[0:6]])\n",
        "\n",
        "pps.score(df, \"sepal-length\",\"class\")\n",
        "\n",
        "df_pps = df[col[0:6]]\n",
        "#df_pps.columns()\n",
        "pps.matrix(df_pps)\n",
        "\n",
        "colorMap = sns.color_palette(\"YlGnBu\", n_colors=5)\n",
        "\n",
        "matrix_df_pps = pps.matrix(df_pps)[['x','y','ppscore']].pivot(columns='x',index='y', values='ppscore')\n",
        "\n",
        "sns.heatmap(matrix_df_pps, vmin=0, vmax=1,cmap=colorMap ,linewidths=0.5,annot=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oPaT-uch4ar7"
      },
      "source": [
        "# Creat pandas dataframe with a list or dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cW3vNM9R4eaR",
        "outputId": "51c4af1b-c618-49d1-9909-0dde33c41719",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        }
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# List\n",
        "lst = [['tom', 'reacher', 25], ['krish', 'pete', 30], \n",
        "       ['nick', 'wilson', 26], ['juli', 'williams', 22]] \n",
        "    \n",
        "df = pd.DataFrame(lst, columns =['FName', 'LName', 'Age'], dtype = float) \n",
        "display(df)\n",
        "\n",
        "\n",
        "#Dictionary\n",
        "dictionary = {\n",
        "    \"First_Name\" :\n",
        "    [\n",
        "     \"tom\", \"nick\"\n",
        "    ],\n",
        "    \"Second_Name\" :\n",
        "    [\n",
        "     \"pete\", \"williams\"\n",
        "    ],\n",
        "    \"Age\" :\n",
        "    [\n",
        "     30,\n",
        "     20\n",
        "    ]\n",
        "}\n",
        "\n",
        "df_2 = pd.DataFrame(dictionary) \n",
        "display(df_2) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FName</th>\n",
              "      <th>LName</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tom</td>\n",
              "      <td>reacher</td>\n",
              "      <td>25.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>krish</td>\n",
              "      <td>pete</td>\n",
              "      <td>30.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>nick</td>\n",
              "      <td>wilson</td>\n",
              "      <td>26.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>juli</td>\n",
              "      <td>williams</td>\n",
              "      <td>22.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   FName     LName   Age\n",
              "0    tom   reacher  25.0\n",
              "1  krish      pete  30.0\n",
              "2   nick    wilson  26.0\n",
              "3   juli  williams  22.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>First_Name</th>\n",
              "      <th>Second_Name</th>\n",
              "      <th>Age</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tom</td>\n",
              "      <td>pete</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nick</td>\n",
              "      <td>williams</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  First_Name Second_Name  Age\n",
              "0        tom        pete   30\n",
              "1       nick    williams   20"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZsXvZxvOdzx"
      },
      "source": [
        "# Text line for print line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AufVb97NOhRO"
      },
      "source": [
        "text_lines = \"\\n\" + \"_\" * 80 + \"\\n\\n\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anQwJkAsdh0r"
      },
      "source": [
        "# Check function in modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioFLuGUNdmLT"
      },
      "source": [
        "help(map)\n",
        "\n",
        "dir(map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeI9HvpDh06P"
      },
      "source": [
        "# Check .methods in modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpmQLry4h4Ik"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKvlIMhOoElk"
      },
      "source": [
        "# Library for work with URL, HTTP, webpage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oxvMZCR9oLwW",
        "outputId": "a7a4f57d-1316-4948-f607-a3b696a6be24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#Begin by importing the Requests module:\n",
        "import requests\n",
        "\n",
        "#Now, let’s try to get a webpage. \n",
        "url = \"https://api.github.com/events\"\n",
        "r = requests.get(url)\n",
        "#Now, we have a Response object called r. We can get all the information we need from this object.\n",
        "\n",
        "#You can also pass a list of items as a value:\n",
        "\n",
        "#payload = {'key1': 'value1', 'key2': ['value2', 'value3']}\n",
        "\n",
        "#r = requests.get('https://httpbin.org/get', params=payload)\n",
        "#print(r.url)\n",
        "#https://httpbin.org/get?key1=value1&key2=value2&key2=value3\n",
        "\n",
        "#Response Content\n",
        "#We can read the content of the server’s response. Consider the GitHub timeline again:\n",
        "r.text\n",
        "\n",
        "#When you make a request, Requests makes educated guesses about the encoding of the response based on the HTTP headers. \n",
        "#The text encoding guessed by Requests is used when you access r.text. You can find out what encoding Requests is using, and change it, using the r.encoding property:\n",
        "\n",
        "print(r.encoding)\n",
        "#Chenge encoding goes like this\n",
        "#r.encoding = 'ISO-8859-1'\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "utf-8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GRP-yuUEuXb"
      },
      "source": [
        "# Library: Scrapy pip install"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPSRa5OWEzcM"
      },
      "source": [
        "!pip install scrapy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8-LeGnJttg9"
      },
      "source": [
        "# Library: Scrapy, Requests (html content, webpage)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iJqdfhpnCY6O"
      },
      "source": [
        "import scrapy\n",
        "import requests\n",
        "import time\n",
        "\n",
        "#Version 1\n",
        "#url = \"xxx\"\n",
        "#html = requests.get(url)\n",
        "\n",
        "#Version 2\n",
        "response = HtmlResponse(url='http://example.com', body=body)\n",
        "response.selector.xpath('//span/text()').get()\n",
        "Selector(response=response).xpath('//span/text()').get()\n",
        "\n",
        "#Version 3\n",
        "url = \"\"\n",
        "\n",
        "html = requests.get( url ).content\n",
        "print(r.status_code)\n",
        "print(r.headers)\n",
        "\n",
        "# Create the Selector object sel from html\n",
        "sel = Selector( text = html )\n",
        "\n",
        "# Example Extract from selector\n",
        "#next_page = sel.css('.mm-product-list-page__pagination').extract()\n",
        "#str_x = str(next_page)\n",
        "#next_page_2 = re.findall(r'(?<=init-pages-quantity=).*$', str_x)\n",
        "#last_page = (int(next_page_2[0].split()[0].replace('\"',\"\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h3VAJ-8oTQjQ"
      },
      "source": [
        "# String methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTEByGWwTT65"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIfS0rfQofky"
      },
      "source": [
        "# Regular Expression with re"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVPyWb6omlgv",
        "outputId": "5d2ae6db-392f-4de5-d1f5-a208d6cdce6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import re\n",
        "\n",
        "text = \"RegExr was created by gskinner.com, and is proudly hosted by Media Temple.Edit the Expression & Text to see matches.\"\n",
        "\n",
        "#help(re)\n",
        "result = re.search(r'(\\w+\\s&)(\\s\\w*)', text)\n",
        "\n",
        "#When using a () inside the reg ex you create groups to be selected\n",
        "result.group(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Text'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmLKRvwU35TE"
      },
      "source": [
        "# Pandas Values count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjwYhiIjsDex"
      },
      "source": [
        "# Show unique values per column in dataframe pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pfh4oChbsIT4"
      },
      "source": [
        "for column in df_train.columns:\n",
        "  print(\"In column %s\" % column)\n",
        "  print(df_train[column].unique())\n",
        "  print(80 * \"_\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D00dIqHCsN1P"
      },
      "source": [
        "# Show count of unique values per column in dataframe pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCShtoxrsOQz"
      },
      "source": [
        "for column in df_train.columns:\n",
        "    print(column, len(df_train[column].dropna().unique()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}